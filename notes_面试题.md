# 机器人规划控制算法

## 机器学习

### 决策树+随机森林+GBDT+XGBoost

bagging：弱分类器之间采取投票或加权的方式组合成强分类器。弱分类器之间没有强依赖关系，可以并行生成。

boosting：弱分类器之间是有强依赖关系，需要序列化生成。

随机森林 是bagging的典型算法

adaboost  GBDT   XGBoost  都是 boosting典型算法

GBDT https://zhuanlan.zhihu.com/p/280222403

- CART 回归树（提升树）
- 负梯度近似残差
- boosting

XGBoost https://zhuanlan.zhihu.com/p/162001079

- 在GBDT的损失函数（均方误差）基础上增加了 正则项



# C++

## 内存分配

内存分配



## 智能指针

智能指针原理与简单实现 https://blog.csdn.net/xiaoyaolangwj/article/details/129612435

### unique_ptr

同⼀时刻只能有⼀个 unique_ptr 指向给定对象，离开作⽤域时，若其指向对象，则自动将其所指对象销毁（默认delete）。 

实现了运算符 `*` 和 `->` 运算符的重载。

```cpp
//构建unique_ptr方式1，需要delete 原始指针
Cat *c_p2 = new Cat("yz");
std::unique_ptr<Cat> u_c_p2{c_p2};
delete c_p2;
c_p2 = nullptr;
u_c_p2->cat_info();

//构建unique_ptr方式2
std::unique_ptr<Cat> u_c_p3{new Cat("dd")};
u_c_p3->cat_info();
u_c_p3->set_cat_name("oo");
u_c_p3->cat_info();

//构建unique_ptr方式3
std::unique_ptr<Cat>u_c_p4 = make_unique<Cat>();
u_c_p4->set_cat_name("oo");
u_c_p4->cat_info();

```

## RAII



## 指针与引用

指针存放某个对象的地址，其本⾝就是变量（命了名的对象），本⾝就有地址，所以可以有指向指针的指针；可变，包括其所**指向的地址**的改变和**其指向的地址中所存放的数据**的改变。

引⽤就是变量的别名，从⼀⽽终，不可变，在创建时必须初始化。

C++ 引用 vs 指针，有三个主要的不同：

- 不存在空引用。引用必须连接到一块合法的内存。但是存在指向空值的指针
- 一旦引用被初始化为一个对象，就不能被指向到另一个对象。指针可以在任何时候指向到另一个对象。
- 引用必须在创建时被初始化。指针可以在任何时间被初始化。

## 值传递、地址传递、引用传递

首先说明的是，参数传递的本质是函数调用栈的参数的copy。

- 值传递：形参是实参的一份临时拷贝，形参和实参分别占不同的地址，对形参的修改不会影响实参。
- 地址传递：传址调用是把函数外部创建变量的内存地址传递给函数参数的一种调用函数的方式。这种传参方式可以让函数和函数外边的变量建立起正真的联系，也就是函数内部可以直接操作函数外部的变量。
- 引用传递：引用相当于给参数取”别名“，两者占用同一个地址，修改”别名“，也会修改原有的参数。

## 字节流





### 强制类型转换



## 关键字

### volatile

volatile 关键字是一种类型修饰符，用它声明的类型变量表示可以被某些编译器未知的因素更改，比如：操作系统、硬件或者其它线程等。因此，遇到这个关键字声明的变量，编译器对访问该变量的代码就不能再进行优化，从而可以提供对特殊地址的稳定访问。声明时语法：`int volatile vInt;` ==当要求使用 volatile 声明的变量值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。而且读取的数据立刻被保存。==例如：

```
volatile int i = 10; 
int a = i;

...

// 其他代码，并未明确告诉编译器，对 i 进行过操作；
int b = i;
```

volatile 指出 i 是随时可能发生变化的，每次使用它的时候必须从 i 的地址中读取，因而编译器生成的汇编代码会重新从i的地址读取数据放在 b 中。而优化做法是，由于编译器发现两次从 i读数据的代码之间的代码没有对 i 进行过操作，它会自动把上次读的数据（例如从 a 中读到的数据）放在 b 中。而不是重新从 i 里面读。这样以来，如果 i是一个寄存器变量或者表示一个端口数据就容易出错，==所以说 volatile 可以保证对特殊地址的稳定访问==。

### const

#### 修饰常量

被const修饰的必须是只读变量，定义时必须初始化。

常量指针：指向常量的指针，被指对象不能通过指针来修改，但是该指针可以指向其他变量。

指针常量：指针为常量。指针本身在定义的时候初始化，并且不能被改变，不能指向别的变量。但是该指针指向的对象的指可以通过该指针来修改。

#### 修饰类成员变量

- 只在某个对象的生命周期内是常量，而对该类实例化的全部对象而言是可变的
- 不能赋值，不能在类外定义;
- 只能通过==构造函数的参数初始化列表初始化==[原因:因为不同的对象对其const数据成员的值可以不同，所以不能在类中声明时初始化]

#### 修饰类成员函数

形式是 `int GetCount(void) const; // const 成员函数`

- 防止 const 成员函数修改对象的内容 [不能修改成员变量的值，但是可以访问]
- const成员函数  不可以  调用非const的函数
- const对象只能访问const成员函数,而非const对象可以访问任意的成员函数,包括const成员函数.
- const对象的成员是不可修改的,然而const对象通过指针维护的对象却是可以修改的.
- const成员函数不可以修改对象的数据,不管对象是否具有const性质.它在编译时,以是否修改成员数据为依据,进行检查.
- 然而加上mutable修饰符的数据成员,对于任何情况下通过任何手段都可修改,自然此时的const成员函数是可以修改它的
  



### static

#### 修饰常量

函数执行结束之后并不会释放对应的内存

#### C语言中使用静态函数

（1）、静态函数会被自动分配在一个一直使用的存储区，直到程序结束才从内存消失，避免调用函数时压栈出栈，速度快很多

（2）、其他文件可以定义相同名字的函数，不会发生冲突

（3）、静态函数不能被其它文件调用，作用于仅限于本文件

#### 修饰类成员变量

*  所有对象共享同一份数据
*  在编译阶段分配内存
*  类内声明，类外初始化

#### 修饰类成员函数

*  所有对象共享同一个函数
*  静态成员函数只能访问static静态成员变量

### new/delete 与 malloc/free

![image-20230423170635694](.\asset\new_malloc.png)

### inline

在C语言中，如果一些函数被频繁调用，不断地有函数入栈，即函数栈，会造成栈空间或栈内存的大量消耗。

为了解决这个问题，特别的引入了inline修饰符，表示为内联函数。

栈空间就是指放置程式的局部数据也就是函数内数据的内存空间，在系统下，栈空间是有限的，假如频繁大量的使用就会造成因栈空间不足所造成的程式出错的问题，函数的死循环递归调用的最终结果就是导致栈内存空间枯竭。

内联函数相当于函数体在程序相应位置展开，而不涉及入栈出栈的操作，减小函数调用的开销。

### extern

定义：声明外部变量【在函数或者⽂件外部定义的全局变量】

### 前置++ 与 后置++

```cpp
struct Test
{
    int m_i;
    //前置++
    Test & operator++()
    {
        ++(this->m_i);
        return *this;
    }
    //后置++
    const Test operator(int)
    {
        Test t = *this;
        ++(*this);
        return t;
    }
};
```

#### 后置++

- 先取值，再增加；
- a++并不是原子操作，因为这一条语句涉及三条机器指令，所以是线程不安全的
- 为了区分前后置，==重载函数是以参数类型来区分==，在调⽤的时候，编译器默默给int指定为⼀个0

#### 前置++

- 先增加，再取值
- 前置++为了可以连续运算，所以会返回对象的引用；
- 后置++会产生临时对象，所以我们最好在满足意图的情况下，优先使用前置++;



## 类

### OOP三大特性

#### 封装：

把客观事物封装成抽象的类，并且类可以把自己的数据和方法只让可信的类或者对象操作，对不可信的进行信息隐藏。 类将成员变量和成员函数封装在类的内部，根据需要设置访问权限，通过成员函数管理内部状态

```cpp
class Person
{
private://数据私有
   string bame;
   int num;
public://方法公有
    void getName()
    {
        return name;
    }
};
```

#### 继承：

继承所表达的是类之间相关的关系，这种关系使得对象可以继承另外一类对象的特征和能力。 继承的作用：避免公用代码的重复开发，减少代码和数据冗余。

```cpp
#include <iostream>
 
using namespace std;
class Base
{
public:
    void printBase(void)
    {
        cout<<"Base中的printBase"<<endl;
    }
};
class Son:public Base
{
 
};
int main(int argc, char *argv[])
{
    Son ob;
    ob.printBase();
    return 0;
}
```

继承方式：

![img](.\asset\clip_image002.png)



继承中 先调用父类构造函数，再调用子类构造函数，析构顺序与构造相反



#### 多态：

一个类实例的相同方法在不同情形下有不同的表现形式，使不同内部结构的对象可以共享相同的外部接口。

多态分为两类

* 静态多态: 函数重载 和 运算符重载属于静态多态，复用函数名
* 动态多态: 派生类和虚函数实现运行时多态

静态多态和动态多态区别：

* 静态多态的函数地址早绑定  -  编译阶段确定函数地址
* 动态多态的函数地址晚绑定  -  运行阶段确定函数地址

多态满足条件

* 有继承关系
* 子类重写父类中的虚函数

多态使用条件

* 父类指针或引用指向子类对象

### 虚继承：用来解决菱形继承

菱形继承是一种错误。可以利用虚继承解决变量二义性。



### 动态多态：虚函数，虚函数表

主要是涉及到多态的底层实现原理，[多态的底层原理（C++程序员Must掌握）](https://blog.csdn.net/xiaoyaolangwj/article/details/122615037)

动态多态：

当父类指针或者引用指向不同的子类对象时，比如指向Cat或者指向Dog的对象。那么就会动态（碰到哪个子类，就去找哪个子类）去寻找这两个子类的虚函数，如果没有，那就直接执行继承的虚函数。如果有，就多态（每个子类都有不同的继承和重写）的执行各自类别的重写的虚函数。

实现方式：虚函数表指针。

这个指针，指向虚函数表：虚函数表中存储的是虚函数的函数入口地址。子类会继承这个虚函数表指针，如果子类重写了这个虚函数，那么子类的虚函数表指针就会指向新的虚函数入口地址。（虚函数表指针指向的变更。）



### 虚析构和纯虚析构

虚析构和纯虚析构：用来解决在多态场景下，delete父类指针之后，子类的析构函数无法调用，如果子类在堆区开辟了内存，则无法在析构函数中对内存释放，造成堆区内存泄露。可以将父类的析构函数设置为虚析构或纯虚析构函数，从而可以调用子类的虚构函数。参考资料：https://blog.csdn.net/xiaoyaolangwj/article/details/122690310



### 深拷贝与浅拷贝

深浅拷贝是面试经典问题，也是常见的一个坑

浅拷贝：简单的赋值拷贝操作，指向同一个内存空间。

深拷贝：在堆区重新申请空间，进行拷贝操作，分别是两块独立的内存空间。

对于类的构造函数，编译器默认提供的是浅拷贝构造函数。但是当存在类中的成员函数需要在堆中申请内存（new）的时候，需要自己重写深拷贝的拷贝构造函数，避免在析构函数中重复释放内存（delete）。



### 静态成员

==只有非静态成员变量会存储在类内，当作类的大小。成员函数和成员变量分开存储。==

静态成员就是在成员变量和成员函数前加上关键字static，称为静态成员

静态成员分为：

*  静态成员变量
   *  所有对象共享同一份数据
   *  在编译阶段分配内存
   *  ==类内声明，类外初始化==
*  静态成员函数
   *  所有对象共享同一个函数
   *  ==静态成员函数只能访问静态成员变量==



1. STL：unordered_map；unordered_set



# 操作系统

## 存储器层次

### CPUCache

CPU Cache 用的是一种叫 **SRAM（\*Static Random-Access\* Memory，静态随机存储器）** 的芯片。

SRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，而一旦断电，数据就会丢失了。

1. L1 Cache
2. L2 Cache
3. L3 Cache

#### 如何确定CPU Cache中保存数据的是要找的内存中的数据的对应的缓存呢？

最简单的方法：**直接映射 Cache（\*Direct Mapped Cache\*）**

- 内存按照内存块的大小 `coherency_line_size` 分为一个个的内存块（block），block的数目为M
- Cache也按照大小 `coherency_line_size` 分为一个个的Cache line，Cache line的数目为 N，每一个Cache line用**Cache line 索引**来表示。
- 将block映射到Cache line上，方法是取余。并且为了区分映射到同一个Cache line的是哪一个block，则利用**组标记**来区分。
- 此外，CPU Cache也会对每一个 Cache line 维护一位 **有效位**，来表示该缓存的数据块是否有效。
- 以上的操作都是在数据块这一个维度上来描述的。那为了进一步找到具体的数据，则是依靠 **地址中的偏移量**来决定的。

![直接映射Cache](asset/直接Cache映射.webp)



CPU 访问一个内存地址的时候，会经历这 4 个步骤：

1. 根据内存地址中索引信息，计算在 CPU Cache 中的索引，也就是找出对应的 CPU Cache Line 的地址；
2. 找到对应 CPU Cache Line 后，判断 CPU Cache Line 中的有效位，确认 CPU Cache Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行；
3. 对比内存地址中组标记和 CPU Cache Line 中的组标记，确认 CPU Cache Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行；
4. 根据内存地址中偏移量信息，从 CPU Cache Line 的数据块中，读取对应的字。



#### 缓存一致性？

如果**数据写入 Cache** 之后，内存与 Cache 相对应的数据将会不同，这种情况下 Cache 和内存数据都不一致了，于是我们肯定是要把 Cache 中的数据同步到内存里的。

有两种机制：写直达和写回

在**写直达**机制中，写入前会先判断数据是否已经在 CPU Cache 里面了：

- 如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；
- 如果数据没有在 Cache 里面，就直接把数据更新到内存里面。

写直达法很直观，也很简单，但是问题明显，无论数据在不在 Cache 里面，每次写操作都会写回到内存，这样写操作将会花费大量的时间，无疑性能会受到很大的影响

在**写回**机制中，**当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中**，减少了数据写回内存的频率，这样便可以提高系统的性能。



如果按照写回机制，在多核处理器中，由于L1/L2 Cache是每个核独有的，所以就会引发**缓存一致性**的问题。

要解决这一问题，就需要一种机制，来同步两个不同核心里面的缓存数据。要实现的这个机制的话，要保证做到下面这 2 点：

- 第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为**写传播（\*Write Propagation\*）**；实现方式：总线嗅探。
- 第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为**事务的串行化（\*Transaction Serialization\*）**。

具体解决方法：MESI协议。

MESI 协议其实是 4 个状态单词的开头字母缩写，分别是：

- *Modified*，已修改
- *Exclusive*，独占
- *Shared*，共享
- *Invalidated*，已失效

这四个状态来标记 Cache Line 四个不同的状态。

![MESI协议](asset/MESI协议.webp)



### 内存

使用的是一种叫作 **DRAM （\*Dynamic Random Access Memory\*，动态随机存取存储器）** 的芯片。

数据会被存储在电容里，电容会不断漏电，所以需要「定时刷新」电容，才能保证数据不会被丢失，这就是 DRAM 之所以被称为「动态」存储器的原因，只有不断刷新，数据才能被存储起来。

### 硬盘

SSD（*Solid-state disk*） 就是我们常说的固体硬盘，结构和内存类似，但是它**相比内存的优点是断电后数据还是存在的，而内存、寄存器、高速缓存断电后数据都会丢失。**内存的读写速度比 SSD 大概快 `10~1000` 倍。



## 内存泄露、雪崩、击穿



## 文件系统



## 自旋锁与互斥锁的区别

加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。

当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：

- **互斥锁**加锁失败后，线程会**释放 CPU** ，给其他线程；
- **自旋锁**加锁失败后，线程会**忙等待**，直到它拿到锁；

### 互斥锁

互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，**既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞**。

**对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的**。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。

### 自旋锁

自旋锁是通过 CPU 提供的 `CAS` 函数（*Compare And Swap*），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。

一般加锁的过程，包含两个步骤：

- 第一步，查看锁的状态，如果锁是空闲的，则执行第二步；
- 第二步，将锁设置为当前线程持有；

CAS 函数就把这两个步骤合并成一条硬件级指令，形成**原子指令**，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。

使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 `while` 循环等待实现，不过最好是使用 CPU 提供的 `PAUSE` 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。

自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。**需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。**



## 嵌入式操作系统

### 中断与异常

中断是异常的一种形式。操作系统中的异常包括中断、陷阱、故障、终止。

中断是指CPU接收到外部硬件产生的一个中断电信号，从而使CPU进入中断状态，处理中断函数。然后返回下一条指令。

陷阱是有意的异常，是执行一条指令的结果。就像中断处理程序一样，陷阱处理程序将控制返回到下一条指令。陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口，叫做系统调用。

故障由错误情况引起，它可能能够被故障处理程序修正。如缺页异常。

终止是不可恢复的致命错误造成的结果，通常是一些硬件错误。

|      |                    |      |                                |
| ---- | ------------------ | ---- | ------------------------------ |
| 中断 | 来自IO设备的信号   | 异步 | 总是返回到下一条指令           |
| 陷阱 | 有意的异常         | 同步 | 总是返回到下一条指令           |
| 故障 | 潜在的可恢复的错误 | 同步 | 可能返回到当前指令；也可能终止 |
| 终止 | 不可恢复的错误     | 同步 | 不会返回                       |

### DMA

DMA是一种无需CPU参与，可以使外设与系统内存之间进行双向数据传输的硬件机制，该过程可以解放CPU，从而提高系统的吞吐率。

### Linux的软中断

Linux 系统**为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」**。

- **上半部用来快速处理中断**，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。
- **下半部用来延迟处理上半部未完成的工作**，一般以「内核线程」的方式运行。

中断处理程序的上部分和下半部可以理解为：

- **上半部直接处理硬件请求，也就是硬中断**，主要是负责耗时短的工作，特点是快速执行；
- **下半部是由内核触发，也就说软中断**，主要是负责上半部未完成的工作，通常都是耗时比较长的事情，特点是延迟执行；

还有一个区别，硬中断（上半部）是会打断 CPU 正在执行的任务，然后立即执行中断处理程序，而软中断（下半部）是以内核线程的方式执行，并且每一个 CPU 都对应一个软中断内核线程，名字通常为「ksoftirqd/CPU 编号」，比如 0 号 CPU 对应的软中断内核线程的名字是 `ksoftirqd/0`

不过，软中断不只是包括硬件设备中断处理程序的下半部，一些内核自定义事件也属于软中断，比如内核调度等、RCU 锁（内核里常用的一种锁）等。

### 中断的上半部和下半部

为了在中断执行时间尽可能短和中断处理需完成大量工作之间找到一个平衡点，Linux将中断处理程序分解为两个半部：顶半部（top half）和底半部（bottom half）。

顶半部完成尽可能少的比较紧急的功能，它往往只是简单地读取寄存器中的中断状态并清除中断标志后就进行“登记中断”的工作。“登记中断”意味着将底半部处理程序挂到该设备的底半部执行队列中去。这样，顶半部执行的速度就会很快，可以服务更多的中断请求。

现在，中断处理工作的重心就落在了底半部的头上，它来完成中断事件的绝大多数任务。底半部几乎做了中断处理程序所有的事情，而且可以被新的中断打断，这也是底半部和顶半部的最大不同，因为顶半部往往被设计成不可中断。底半部则相对来说并不是非常紧急的，而且相对比较耗时，不在硬件中断服务程序中执行。

中断要尽可能耗时比较短，尽快恢复系统正常调试，所以把中断触发、中断执行分开，也就是所说的“上半部分（中断触发）、底半部（中断执行）”，其实就是我们后面说的中断上下文。下半部分一般有tasklet、工作队列实现，触摸屏中中断实现以工作队列形式实现的

https://www.cnblogs.com/mysky007/p/12309553.html

### 中断和轮询哪一个效率更高？

中断是CPU接收到请求之后再去处理请求。轮询则是CPU每隔固定时间主动查询是否有请求。

如果请求设备频繁请求CPU，或者大量数据请求，那么轮询效率更高。一般设备，请求频率较低则中断效率更高。

## 嵌入式通信

### 异步传输 同步传输



### RS232 与 RS485



### SPI协议

SPI是［单主设备（ single-master ）］通信协议，这意味着总线中的只有一支中心设备能发起通信。当SPI主设备想读/写［从设备］时，它首先拉低［从设备］对应的SS线（SS是低电平有效），接着开始发送工作脉冲到时钟线上，在相应的脉冲时间上，［主设备］把信号发到MOSI实现“写”，同时可对MISO采样而实现“读”

SCLK：Serial Clock (output from master);

MOSI;SIMO：Master Output，Slave Input;

MISO;SOMI：Master Input，Slave Output;

SS：Slave Select (active low)。

SPI有四种操作模式——模式0、模式1、模式2和模式3，它们的区别是定义了==在时钟脉冲的哪条边沿转换（toggles）输出信号，哪条边沿采样输入信号，还有时钟脉冲的稳定电平值（就是时钟信号无效时是高还是低）==。

每种模式由一对参数刻画，它们称为时钟极（clock polarity）CPOL与时钟期（clock phase）CPHA。

![SPI-4-mode](.\asset\SPI-4-mode.webp)

［主从设备］必须使用相同的工作参数——SCLK、CPOL 和 CPHA，才能正常工作。如果有多个［从设备］，并且它们使用了不同的工作参数，那么［主设备］必须在读写不同［从设备］间重新配置这些参数。

### IIC协议

IIC 是多主设备的总线，IIC没有物理的芯片选择信号线，没有仲裁逻辑电路，只使用两条信号线—— ‘serial data’ (SDA) 和 ‘serial clock’ (SCL)。IIC协议规定：

- 第一，每一支IIC设备都有一个唯一的七位设备地址；
- 第二，数据帧大小为8位的字节；
- 第三，数据（帧）中的某些数据位用于控制通信的开始、停止、方向（读写）和应答机制。

IIC 数据传输速率有标准模式（100 kbps）、快速模式（400 kbps）和高速模式（3.4 Mbps），另外一些变种实现了低速模式（10 kbps）和快速+模式（1 Mbps）。

IIC 通信过程大概如下。首先，主设备发一个START信号，这个信号就像对所有其它设备喊：请大家注意！然后其它设备开始监听总线以准备接收数据。接着，主设备发送一个7位设备地址加一位的读写操作的数据帧。当所设备接收数据后，比对地址自己是否目标设备。如果比对不符，设备进入等待状态，等待STOP信号的来临；如果比对相符，设备会发送一个应答信号——ACKNOWLEDGE作回应。

# 计网

1. TCP三次握手 四次挥手
2. TCP：一个TCP连接中，分别介绍服务器被拔网线、宕机、进程被kill会发生什么
3. HTTP：http连接服务器和客户端什么情况下会断开





# 数据库



